name: Subdomain & Vulnerability scaaner & delta

on:
  workflow_dispatch:
    inputs:
      domain:
        description: 'Domain to scan (optional). If omitted, workflow will use targets.txt if present.'
        required: false
        default: ''
  schedule:
    - cron: '0 6 * * 1'  # Every Monday at 6 AM UTC

permissions:
  contents: write
  issues: write

jobs:
  scan:
    runs-on: ubuntu-latest
    env:
      RESULTS_DIR: results
      TARGETS_FILE: targets.txt
      GITHUB_USER_NAME: github-actions[bot]
      GITHUB_USER_EMAIL: github-actions[bot]@users.noreply.github.com
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          persist-credentials: true

      - name: Setup Go
        uses: actions/setup-go@v4
        with:
          go-version: '1.21'

      - name: Install packages & tools
        run: |
          set -euo pipefail
          sudo apt-get update -y
          sudo apt-get install -y jq unzip wget git build-essential ca-certificates
          # ensure go bin in PATH for later steps
          echo "GOBIN=$HOME/go/bin" >> $GITHUB_ENV
          echo "PATH=$PATH:$HOME/go/bin" >> $GITHUB_ENV
          export GOBIN=$HOME/go/bin
          export PATH=$PATH:$HOME/go/bin
          export CGO_ENABLED=0
          export GOFLAGS="-mod=mod"
          # Install tools (non-fatal if fails)
          go install -v github.com/projectdiscovery/subfinder/v2/cmd/subfinder@latest || true
          go install -v github.com/tomnomnom/assetfinder@latest || true
          go install -v github.com/projectdiscovery/httpx/cmd/httpx@latest || true
          go install -v github.com/projectdiscovery/nuclei/v3/cmd/nuclei@latest || true
          echo "Tool availability (may be empty if install failed):"
          which subfinder || true
          which assetfinder || true
          which httpx || true
          which nuclei || true

      - name: Validate DISCORD secret
        run: |
          if [ -z "${{ secrets.DISCORD_WEBHOOK_URL }}" ]; then
            echo "::error::DISCORD_WEBHOOK_URL secret is not set"
            exit 1
          fi
          echo "DISCORD_WEBHOOK_URL=${{ secrets.DISCORD_WEBHOOK_URL }}" >> $GITHUB_ENV

      - name: Prepare results folder & runstamp
        run: |
          mkdir -p "${{ env.RESULTS_DIR }}"
          TIMESTAMP=$(date -u +"%Y%m%dT%H%M%SZ")
          echo "RUNSTAMP=$TIMESTAMP" >> $GITHUB_ENV
          mkdir -p "${{ env.RESULTS_DIR }}/$TIMESTAMP"

      - name: Prepare domains list (workflow_dispatch input > targets.txt > default example.com)
        run: |
          # choose domains list:
          if [ "${{ github.event_name }}" = "workflow_dispatch" ] && [ -n "${{ github.event.inputs.domain }}" ]; then
            echo "${{ github.event.inputs.domain }}" > domains_list.txt
          elif [ -f "${{ env.TARGETS_FILE }}" ]; then
            cp "${{ env.TARGETS_FILE }}" domains_list.txt
          else
            echo "example.com" > domains_list.txt
          fi
          echo "Using domains from domains_list.txt:"
          cat domains_list.txt

      - name: Notify start (Discord)
        run: |
          DOMAIN_PREVIEW=$(head -n 5 domains_list.txt | tr '\n' ',' | sed 's/,$//')
          PAYLOAD=$(jq -n --arg d "$DOMAIN_PREVIEW" --arg t "${{ env.RUNSTAMP }}" \
            '{content: ("🔍 **Scan Started**\n**Domains:** "+$d+"\n**Run:** "+$t+"\n**Trigger:** '+(env.GITHUB_EVENT_NAME||"scheduled")+' \n**Tools:** Subfinder + Assetfinder + httpx + Nuclei")}')
          curl -s -X POST -H "Content-Type: application/json" -d "$PAYLOAD" "${{ env.DISCORD_WEBHOOK_URL }}" || true

      - name: Discover subdomains (subfinder + assetfinder)
        run: |
          OUT_DIR="${{ env.RESULTS_DIR }}/${{ env.RUNSTAMP }}"
          > "$OUT_DIR/subs_raw.txt"
          while IFS= read -r domain; do
            if [ -z "$domain" ]; then continue; fi
            echo "[+] subfinder: $domain"
            subfinder -d "$domain" -silent >> "$OUT_DIR/subs_raw.txt" || true
            echo "[+] assetfinder: $domain"
            assetfinder --subs-only "$domain" >> "$OUT_DIR/subs_raw.txt" || true
          done < domains_list.txt
          sort -u "$OUT_DIR/subs_raw.txt" -o "$OUT_DIR/subs_raw.txt"
          # save a compact subdomains list
          awk 'NF' "$OUT_DIR/subs_raw.txt" > "$OUT_DIR/subdomains_all.txt"
          cp "$OUT_DIR/subdomains_all.txt" subdomains.txt || true
          echo "DISCOVERED_SUBDOMAINS=$(wc -l < "$OUT_DIR/subdomains_all.txt")" >> $GITHUB_ENV

      - name: Resolve & probe alive (httpx)
        run: |
          OUT_DIR="${{ env.RESULTS_DIR }}/${{ env.RUNSTAMP }}"
          cat "$OUT_DIR/subdomains_all.txt" | httpx -silent -status-code -title -threads 50 -o "$OUT_DIR/alive.txt" || true
          # ensure files exist
          [ -f "$OUT_DIR/alive.txt" ] || touch "$OUT_DIR/alive.txt"
          cp "$OUT_DIR/alive.txt" alive.txt || true
          echo "ALIVE_COUNT=$(wc -l < \"$OUT_DIR/alive.txt\")" >> $GITHUB_ENV

      - name: Run nuclei (JSONL -> JSON)
        run: |
          OUT_DIR="${{ env.RESULTS_DIR }}/${{ env.RUNSTAMP }}"
          nuclei -l "$OUT_DIR/alive.txt" -severity critical,high,medium -json -o "$OUT_DIR/nuclei.jsonl" || true
          # make a JSON array for jq
          if [ -f "$OUT_DIR/nuclei.jsonl" ]; then
            jq -s '.' "$OUT_DIR/nuclei.jsonl" > "$OUT_DIR/nuclei.json" || echo "[]" > "$OUT_DIR/nuclei.json"
          else
            echo "[]" > "$OUT_DIR/nuclei.json"
          fi
          cp "$OUT_DIR/nuclei.json" nuclei-results.json || true
          # also keep a plain text representation for messages
          jq -r '.[] | "[" + (.info.severity // "unknown") + "] " + (.template.id // "") + " -> " + (.host // "") + " " + (.matched // "" )' "$OUT_DIR/nuclei.json" > "$OUT_DIR/nuclei_readable.txt" || true
          [ -f "$OUT_DIR/nuclei_readable.txt" ] || touch "$OUT_DIR/nuclei_readable.txt"
          cp "$OUT_DIR/nuclei_readable.txt" nuclei-results.txt || true
          echo "NUCLEI_VULNS_FOUND=$(wc -l < \"$OUT_DIR/nuclei_readable.txt\")" >> $GITHUB_ENV

      - name: Prepare previous-run placeholders
        run: |
          OUT_DIR="${{ env.RESULTS_DIR }}/${{ env.RUNSTAMP }}"
          # ensure last files exist to diff against
          touch "${{ env.RESULTS_DIR }}/last_subdomains.txt"
          [ -f "${{ env.RESULTS_DIR }}/last_nuclei.json" ] || echo "[]" > "${{ env.RESULTS_DIR }}/last_nuclei.json"
          # copy last to workspace for comparing
          cp "${{ env.RESULTS_DIR }}/last_subdomains.txt" "${{ env.RESULTS_DIR }}/prev_subdomains.txt" || true
          cp "${{ env.RESULTS_DIR }}/last_nuclei.json" "${{ env.RESULTS_DIR }}/prev_nuclei.json" || true

      - name: Diff subdomains (added / removed)
        run: |
          OUT_DIR="${{ env.RESULTS_DIR }}/${{ env.RUNSTAMP }}"
          sort -u "${{ env.RESULTS_DIR }}/prev_subdomains.txt" -o "${{ env.RESULTS_DIR }}/prev_subdomains_sorted.txt" || true
          sort -u "$OUT_DIR/subdomains_all.txt" -o "$OUT_DIR/subdomains_all_sorted.txt" || true
          comm -23 "$OUT_DIR/subdomains_all_sorted.txt" "${{ env.RESULTS_DIR }}/prev_subdomains_sorted.txt" > "$OUT_DIR/added_subdomains.txt" || true
          comm -13 "$OUT_DIR/subdomains_all_sorted.txt" "${{ env.RESULTS_DIR }}/prev_subdomains_sorted.txt" > "$OUT_DIR/removed_subdomains.txt" || true
          cp "$OUT_DIR/added_subdomains.txt" added_subdomains.txt || true
          cp "$OUT_DIR/removed_subdomains.txt" removed_subdomains.txt || true

      - name: Diff nuclei findings (added / removed)
        run: |
          OUT_DIR="${{ env.RESULTS_DIR }}/${{ env.RUNSTAMP }}"
          # parse nuclei to "template|host|severity" lines
          jq -r '.[] | "\(.template.id)//\(.host)//\(.info.severity // "")"' "$OUT_DIR/nuclei.json" | sort -u > "$OUT_DIR/new_nuclei_parsed.txt"
          jq -r '.[] | "\(.template.id)//\(.host)//\(.info.severity // "")"' "${{ env.RESULTS_DIR }}/prev_nuclei.json" | sort -u > "${{ env.RESULTS_DIR }}/prev_nuclei_parsed.txt" || true
          comm -23 "$OUT_DIR/new_nuclei_parsed.txt" "${{ env.RESULTS_DIR }}/prev_nuclei_parsed.txt" > "$OUT_DIR/added_nuclei.txt" || true
          comm -13 "$OUT_DIR/new_nuclei_parsed.txt" "${{ env.RESULTS_DIR }}/prev_nuclei_parsed.txt" > "$OUT_DIR/removed_nuclei.txt" || true
          cp "$OUT_DIR/added_nuclei.txt" added_nuclei.txt || true
          cp "$OUT_DIR/removed_nuclei.txt" removed_nuclei.txt || true

      - name: Create GitHub Issue if HIGH/CRITICAL new findings
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            const addedPath = 'added_nuclei.txt';
            if (!fs.existsSync(addedPath)) return;
            const content = fs.readFileSync(addedPath,'utf8').trim();
            if (!content) return;
            const lines = content.split(/\r?\n/).filter(Boolean);
            const high = lines.filter(l => /critical|high/i.test(l));
            if (!high.length) return;
            const body = `Automated scan detected new HIGH/CRITICAL findings (run: ${process.env.RUNSTAMP}):\n\n\`\`\`\n${high.slice(0,100).join('\n')}\n\`\`\``;
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `Automated: HIGH/CRITICAL findings - ${process.env.RUNSTAMP}`,
              body,
              labels: ['automated-scan','high-priority']
            });

      - name: Build weekly summary message for Discord (always send)
        id: build_message
        run: |
          OUT_DIR="${{ env.RESULTS_DIR }}/${{ env.RUNSTAMP }}"
          ADDED_SUBS=$(awk 'NF' "$OUT_DIR/added_subdomains.txt" | wc -l || echo 0)
          REMOVED_SUBS=$(awk 'NF' "$OUT_DIR/removed_subdomains.txt" | wc -l || echo 0)
          ADDED_NUC=$(awk 'NF' "$OUT_DIR/added_nuclei.txt" | wc -l || echo 0)
          REMOVED_NUC=$(awk 'NF' "$OUT_DIR/removed_nuclei.txt" | wc -l || echo 0)
          TOTAL_SUBS=$(wc -l < "$OUT_DIR/subdomains_all.txt" || echo 0)
          TOTAL_ALIVE=$(wc -l < "$OUT_DIR/alive.txt" || echo 0)
          TOTAL_NUC=$(wc -l < "$OUT_DIR/nuclei_readable.txt" || echo 0)

          # prepare human readable snippet (truncate if too long)
          ADDED_SUBS_SNIPPET=$(head -n 50 "$OUT_DIR/added_subdomains.txt" | sed ':a;N;$!ba;s/\n/\\n/g' || echo "")
          ADDED_NUC_SNIPPET=$(head -n 50 "$OUT_DIR/added_nuclei.txt" | sed ':a;N;$!ba;s/\n/\\n/g' || echo "")

          SUMMARY="**Weekly Scan Report**\nRun: ${{ env.RUNSTAMP }}\nDomains scanned: $(wc -l < domains_list.txt || echo 1)\nTotal discovered subdomains: $TOTAL_SUBS\nAlive hosts: $TOTAL_ALIVE\nNuclei findings (crit/high/med): $TOTAL_NUC\n\nAdded subdomains: $ADDED_SUBS\nRemoved subdomains: $REMOVED_SUBS\nAdded findings: $ADDED_NUC\nRemoved findings: $REMOVED_NUC\n\nNew subdomains (top 50):\\n$ADDED_SUBS_SNIPPET\n\nNew findings (top 50):\\n$ADDED_NUC_SNIPPET"

          # write JSON payload
          echo "PAYLOAD=$(jq -n --arg c \"$SUMMARY\" '{content:$c}')" >> $GITHUB_ENV

      - name: Send weekly report to Discord
        run: |
          curl -s -X POST -H "Content-Type: application/json" -d "${{ env.PAYLOAD }}" "${{ env.DISCORD_WEBHOOK_URL }}" || true

      - name: Save new results as last_* and commit
        run: |
          OUT_DIR="${{ env.RESULTS_DIR }}/${{ env.RUNSTAMP }}"
          # update last pointers
          cp "$OUT_DIR/subdomains_all.txt" "${{ env.RESULTS_DIR }}/last_subdomains.txt" || true
          cp "$OUT_DIR/nuclei.json" "${{ env.RESULTS_DIR }}/last_nuclei.json" || true
          # also store the run folder (timestamped)
          git config user.name "${{ env.GITHUB_USER_NAME }}"
          git config user.email "${{ env.GITHUB_USER_EMAIL }}"
          git add "${{ env.RESULTS_DIR }}/$RUNSTAMP" "${{ env.RESULTS_DIR }}/last_subdomains.txt" "${{ env.RESULTS_DIR }}/last_nuclei.json"
          git commit -m "Automated scan results: $RUNSTAMP" || echo "No changes to commit"
          git push origin HEAD:${{ github.ref_name }} || true

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: scan-results-${{ env.RUNSTAMP }}
          path: ${{ env.RESULTS_DIR }}/${{ env.RUNSTAMP }}

